{"cells":[{"cell_type":"markdown","source":["**Attention:** This notebook requires Linux to run and create the dataset. If you do not have a Linux PC, please execute this code in Colab and download the final result."],"metadata":{"id":"gjgWYvNY16Rg"}},{"cell_type":"code","source":["# Loading and unzipping the raw data set\n","import gdown\n","import zipfile\n","\n","# Raw data\n","archive_url = 'https://drive.google.com/file/d/1YDZ2XB2Jdbot1SDptyaD36gobWKSl0oi/view?usp=share_link'\n","\n","output_archive = '/content/archive.zip'\n","gdown.download(archive_url, output_archive, quiet=False, fuzzy = True)\n","!unzip /content/archive.zip\n","!mv /content/kaggle/kaggle/train /content\n","!rm -rf kaggle\n","!rm archive.zip"],"metadata":{"id":"bgzFEaqN17jr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlxD87Nh0I5T"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n","from skimage import exposure\n","from skimage.color import rgb2gray\n","import cv2\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vi1qNK8H0I5X"},"outputs":[],"source":["# Setting the data paths\n","\n","data_path = '/content/'\n","data_dir = '/content/train/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYnFHgsx0I5Y"},"outputs":[],"source":["# As the raw data set contains a few corrupted images, this code iterates over all\n","# images and validates the data. If the file is found to be corrupt, it is ommited\n","# from the final dataset. \n","\n","errors = []\n","\n","for image in os.listdir(data_dir):\n","  try:\n","    img = Image.open(data_dir + image) # open the image file\n","    img.verify() # verify that it is, in fact an image\n","  except (IOError, SyntaxError) as e:\n","    print('Bad file:', image, data_dir) # print out the names of corrupt files\n","    errors.append(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAxsXw4I0I5e"},"outputs":[],"source":["# read the label files provided by the dataset\n","\n","train_age = pd.read_csv(data_path + 'train_age.csv')\n","train_gender = pd.read_csv(data_path + 'train_gender.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gw522BTM0I5h"},"outputs":[],"source":["# Create a csv-file that contains the combined label for each image\n","# For the combined label, the age group and the gender are combined as a string\n","# using '-' as a seperator\n","\n","train_full_cohort = train_age\n","train_full_cohort['age'] = train_full_cohort['age'].apply(lambda x: round(x))\n","# group age into cohorts of 5 years starting from 15\n","for i in range(15, 100, 5):\n","    train_full_cohort['age'] = np.where((train_full_cohort['age'] >= i) & (train_full_cohort['age'] < i + 5), i, train_full_cohort['age'])\n","train_full_cohort['gender'] = train_gender['gender'].astype(str)\n","train_full_cohort['age'] = train_full_cohort['age'].astype(str)\n","train_full_cohort['combine'] = train_full_cohort[['age', 'gender']].agg('-'.join, axis=1)\n","train_full_cohort.to_csv(data_path + 'train_full_cohort.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3jTErMP0I5j"},"outputs":[],"source":["# Creating the csv-files containing ids for the different classes\n","\n","!mkdir /content/cohorts_5\n","for label in train_full_cohort['combine'].unique():\n","    df = train_full_cohort[train_full_cohort['combine'] == label]\n","    ids = []\n","    for id in df['imageId']:\n","        # fill the image-id with 0 from the left, as the image names on disk\n","        # have this format and python ommits preceeding zeros\n","        id = str(id).zfill(6)\n","        # add the .png extension\n","        id = id + '.png'\n","        if id not in errors:\n","          ids.append(id)\n","        else: \n","          print(id)\n","        #create a csv file with the imageIds for this label\n","    ids = pd.DataFrame(ids)\n","    ids.to_csv(data_path + 'cohorts_5/' + str(label) + '.csv', index=False, header=False)"]},{"cell_type":"code","source":["# download the bash script to create the folder structure and move all the \n","# images into their respective folders\n","\n","script_url = 'https://drive.google.com/file/d/1EcMuDdsfpoEQypps03EUcBpceWhN4eQ8/view?usp=share_link'\n","script_output = '/content/split.sh'\n","gdown.download(script_url, script_output, quiet = False, fuzzy = True)"],"metadata":{"id":"MSt25iobhtB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make the script executable, create the data directory and run the script\n","!chmod +x /content/split.sh\n","!mkdir data\n","!/content/split.sh"],"metadata":{"id":"QMy_jXLRA4g3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a zip-file of the final dataset\n","!zip -r /content/cohorts_5.zip data/"],"metadata":{"id":"x68sO7qUB5w3"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"tf-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4,"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}